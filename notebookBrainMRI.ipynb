{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8074309,"sourceType":"datasetVersion","datasetId":4764787}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import packages","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras import regularizers, layers\n\nfrom collections import defaultdict\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:45:00.574083Z","iopub.execute_input":"2024-04-19T08:45:00.574916Z","iopub.status.idle":"2024-04-19T08:45:15.61013Z","shell.execute_reply.started":"2024-04-19T08:45:00.574886Z","shell.execute_reply":"2024-04-19T08:45:15.609018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup datasets","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 224\nUSE_AUGUMENTATION = False\nINPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\nBATCH_SIZE = 16\nEPOCHS = 60","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:45:15.612765Z","iopub.execute_input":"2024-04-19T08:45:15.613983Z","iopub.status.idle":"2024-04-19T08:45:15.61875Z","shell.execute_reply.started":"2024-04-19T08:45:15.613942Z","shell.execute_reply":"2024-04-19T08:45:15.61757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"brain-mri\"\ndataset_paths = [\n    '/kaggle/input/brain-mri-224x224/Training',\n    '/kaggle/input/brain-mri-224x224/Testing'\n]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:45:15.620295Z","iopub.execute_input":"2024-04-19T08:45:15.620738Z","iopub.status.idle":"2024-04-19T08:45:15.671047Z","shell.execute_reply.started":"2024-04-19T08:45:15.620698Z","shell.execute_reply":"2024-04-19T08:45:15.670118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = [\n    'notumor', \n    'glioma', \n    'pituitary', \n    'meningioma'\n]\nnum_classes = len(classes)\nclasses","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:45:15.672206Z","iopub.execute_input":"2024-04-19T08:45:15.672531Z","iopub.status.idle":"2024-04-19T08:45:15.692017Z","shell.execute_reply.started":"2024-04-19T08:45:15.672504Z","shell.execute_reply":"2024-04-19T08:45:15.691018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dict = defaultdict(list)\nerror_count = 0\nimage_paths = []\nimages = []\nlabels = []\n\nlimit = 2000\n\nfor path in dataset_paths:\n    for dirpath, _, filenames in os.walk(path):\n        for filename in tqdm(filenames):\n            label = dirpath.split('/')[-1]\n            if label not in classes: continue\n            if len(data_dict[label]) >= limit: continue\n            try:\n                path = os.path.join(dirpath, filename)\n                image = cv2.imread(path) # Check for no error\n                image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                data_dict[label].append(image)\n                image_paths.append(path)\n                images.append(image)\n                labels.append(label)\n            except:\n#                 print('ERROR: ', filename)\n                error_count += 1\n\nprint(\"ErrorCount:\", error_count)\nprint(\"Total Images:\", len(images))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:45:15.695651Z","iopub.execute_input":"2024-04-19T08:45:15.69596Z","iopub.status.idle":"2024-04-19T08:46:31.580516Z","shell.execute_reply.started":"2024-04-19T08:45:15.695935Z","shell.execute_reply":"2024-04-19T08:46:31.579648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9, 3))\nsns.countplot(y=pd.Series(labels))\nplt.title(\"\\nThe number of images on each labels\\n\", weight=\"bold\")\nplt.xlabel(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:31.581636Z","iopub.execute_input":"2024-04-19T08:46:31.581914Z","iopub.status.idle":"2024-04-19T08:46:31.943548Z","shell.execute_reply.started":"2024-04-19T08:46:31.58189Z","shell.execute_reply":"2024-04-19T08:46:31.942604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams.update({'font.size': 14})\n\ndef visualize_datasets(images, labels, k=4, cols=4, seed=42):\n    # visualize datasets\n\n    if k > len(images): k = len(images)\n    rows = int(np.ceil(k / cols))\n    fig = plt.figure(figsize=(6 * cols, 4 * rows))\n\n    for i in range(k):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.title.set_text(labels[i])\n        plt.imshow(images[i])\n        plt.colorbar()\n        plt.axis('off')\n\n    plt.show()\n\nsample_images = [data_dict[k][0] for k in data_dict]\nvisualize_datasets(sample_images, list(data_dict.keys()), k=len(data_dict), cols=4)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:31.945075Z","iopub.execute_input":"2024-04-19T08:46:31.945407Z","iopub.status.idle":"2024-04-19T08:46:33.051485Z","shell.execute_reply.started":"2024-04-19T08:46:31.94538Z","shell.execute_reply":"2024-04-19T08:46:33.050511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode datasets","metadata":{}},{"cell_type":"code","source":"# Convert labels to numpy array\nx = np.stack(images, axis=0)\ny = tf.one_hot([classes.index(label) for label in labels], num_classes).numpy()\n\nx.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:33.053034Z","iopub.execute_input":"2024-04-19T08:46:33.05407Z","iopub.status.idle":"2024-04-19T08:46:33.995256Z","shell.execute_reply.started":"2024-04-19T08:46:33.054031Z","shell.execute_reply":"2024-04-19T08:46:33.994351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split datasets","metadata":{}},{"cell_type":"code","source":"# Split the data into training and remaining sets (validation + test)\nx_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n# Split the remaining data into validation and test sets\nx_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n\n[\n    x_train.shape, \n    x_val.shape, \n    x_test.shape, \n    y_train.shape , \n    y_val.shape , \n    y_test.shape\n]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:33.996351Z","iopub.execute_input":"2024-04-19T08:46:33.996978Z","iopub.status.idle":"2024-04-19T08:46:34.444128Z","shell.execute_reply.started":"2024-04-19T08:46:33.99695Z","shell.execute_reply":"2024-04-19T08:46:34.443158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"def plot_acc(model_history, name):\n    plt.rcParams.update({'font.size': 14})\n    print('\\n\\n')\n    epochs = len(model_history.history[\"accuracy\"])\n    plt.figure(figsize=(12,8))\n    plt.plot(np.arange(0, epochs), model_history.history[\"accuracy\"], label=\"train_acc\", marker=\"o\")\n    plt.plot(np.arange(0, epochs), model_history.history[\"val_accuracy\"], label=\"val_acc\", marker=\"o\")\n    plt.title(\"Training Accuracy - {}\".format(name))\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.445331Z","iopub.execute_input":"2024-04-19T08:46:34.445625Z","iopub.status.idle":"2024-04-19T08:46:34.453586Z","shell.execute_reply.started":"2024-04-19T08:46:34.4456Z","shell.execute_reply":"2024-04-19T08:46:34.4525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(model_history, name):\n    plt.rcParams.update({'font.size': 14})\n    print('\\n\\n')\n    epochs = len(model_history.history[\"loss\"])\n    plt.figure(figsize=(12,8))\n    plt.plot(np.arange(0, epochs), model_history.history[\"loss\"], label=\"train_loss\", marker=\"o\")\n    plt.plot(np.arange(0, epochs), model_history.history[\"val_loss\"], label=\"val_loss\", marker=\"o\")\n    plt.title(\"Training Loss - {}\".format(name))\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.454588Z","iopub.execute_input":"2024-04-19T08:46:34.454877Z","iopub.status.idle":"2024-04-19T08:46:34.464001Z","shell.execute_reply.started":"2024-04-19T08:46:34.454854Z","shell.execute_reply":"2024-04-19T08:46:34.463074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.rcParams.update({'font.size': 14})\n    \n    # plot the confusion matrix\n    class_count = len(classes)\n    if normalize:\n        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n        \n    plt.figure(figsize=(12, 8))\n    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n    plt.xticks(np.arange(class_count) + 0.5, classes, rotation=90)\n    plt.yticks(np.arange(class_count) + 0.5, classes, rotation=0)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.465051Z","iopub.execute_input":"2024-04-19T08:46:34.465327Z","iopub.status.idle":"2024-04-19T08:46:34.477272Z","shell.execute_reply.started":"2024-04-19T08:46:34.465298Z","shell.execute_reply":"2024-04-19T08:46:34.476474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, x, y):\n    scores = model.evaluate(x, y, verbose=1)\n    return scores","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.478332Z","iopub.execute_input":"2024-04-19T08:46:34.478589Z","iopub.status.idle":"2024-04-19T08:46:34.491692Z","shell.execute_reply.started":"2024-04-19T08:46:34.478567Z","shell.execute_reply":"2024-04-19T08:46:34.490897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_prob(model):\n    return model.predict(x_test, batch_size=BATCH_SIZE, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.495511Z","iopub.execute_input":"2024-04-19T08:46:34.49582Z","iopub.status.idle":"2024-04-19T08:46:34.502873Z","shell.execute_reply.started":"2024-04-19T08:46:34.495798Z","shell.execute_reply":"2024-04-19T08:46:34.501995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model):\n    predictions = predict_prob(model)\n    return np.argmax(predictions, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.503898Z","iopub.execute_input":"2024-04-19T08:46:34.504175Z","iopub.status.idle":"2024-04-19T08:46:34.513006Z","shell.execute_reply.started":"2024-04-19T08:46:34.504153Z","shell.execute_reply":"2024-04-19T08:46:34.512153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_metrics(y_true, y_pred):\n    \n    print(\"Visualize: y_true, y_pred top 20\")\n    print('Y_true', [i for i in y_true[:20]])\n    print('Y_pred', [j for j in y_pred[:20]])\n\n    # precision tp / (tp + fp)\n    precision = precision_score(y_true, y_pred, average='weighted')\n    print(\"Precision: {}\".format(precision))\n\n    # recall: tp / (tp + fn)\n    recall = recall_score(y_true, y_pred, average='weighted')\n    print(\"Recall:    {}\".format(recall))\n\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    print(\"F1:        {}\".format(f1))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.514182Z","iopub.execute_input":"2024-04-19T08:46:34.514761Z","iopub.status.idle":"2024-04-19T08:46:34.524024Z","shell.execute_reply.started":"2024-04-19T08:46:34.514737Z","shell.execute_reply":"2024-04-19T08:46:34.52325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup Training","metadata":{}},{"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    mode='max',\n    patience=15,\n    restore_best_weights=True,\n    verbose=1,\n)\n\n# Custom callback for reducing learning rate at accuracy values\nclass ReduceLROnMultipleAccuracies(tf.keras.callbacks.Callback):\n    \n    def __init__(self, thresholds, factor, monitor='val_accuracy', verbose=1):\n        super(ReduceLROnMultipleAccuracies, self).__init__()\n        self.thresholds = thresholds  # List of accuracy thresholds\n        self.factor = factor  # Factor to reduce the learning rate\n        self.monitor = monitor\n        self.verbose = verbose\n        self.thresholds_reached = [False] * len(thresholds)  # Track each threshold\n\n    def on_epoch_end(self, epoch, logs=None):\n        current_accuracy = logs.get(self.monitor)\n        for i, threshold in enumerate(self.thresholds):\n            if current_accuracy >= threshold and not self.thresholds_reached[i]:\n                optimizer = self.model.optimizer\n                old_lr = optimizer.learning_rate.numpy()\n                new_lr = old_lr * self.factor\n                optimizer.learning_rate.assign(new_lr)\n                self.thresholds_reached[i] = True  # Mark this threshold as reached\n                if self.verbose > 0:\n                    print(f\"\\nEpoch {epoch+1}: {self.monitor} reached {threshold}. Reducing learning rate from {old_lr} to {new_lr}.\")\n\n# Try a custom callback\nthresholds = [0.96, 0.99, 0.9935]\nlr_callback = ReduceLROnMultipleAccuracies(thresholds=thresholds, factor=0.75, monitor='val_accuracy', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.52529Z","iopub.execute_input":"2024-04-19T08:46:34.525564Z","iopub.status.idle":"2024-04-19T08:46:34.536202Z","shell.execute_reply.started":"2024-04-19T08:46:34.525541Z","shell.execute_reply":"2024-04-19T08:46:34.535435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transfer_learning(model, name):\n    \n    best_weights_ph1 = f\"{dataset_name}_{name}_ph1_weights.keras\"\n    \n    callbacks_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath = best_weights_ph1,\n        monitor = \"val_accuracy\",\n        mode = \"max\",\n        save_weights_only=True,\n        save_best_only = True,\n        verbose=1, # Logging when callback running\n    )\n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n    model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n    history = model.fit(\n        x_train,\n        y_train,\n        batch_size=BATCH_SIZE,\n        validation_data=(x_val, y_val),\n        validation_batch_size=BATCH_SIZE,\n        epochs = EPOCHS,\n        callbacks = [callbacks_checkpoint, early_stop]\n    )\n    \n    acc_max = max(history.history[\"accuracy\"])\n    acc_min = min(history.history[\"accuracy\"])\n    print(\"Training Acc:\", [acc_min, acc_max])\n    \n    val_acc_max = max(history.history[\"val_accuracy\"])\n    val_acc_min = min(history.history[\"val_accuracy\"])\n    print(\"Validation Acc:\", [val_acc_min, val_acc_max])\n    \n    best_idx = np.argmax(history.history[\"val_accuracy\"])\n    print('The best val_acc result expected at epoch {} with metrics: '.format(best_idx + 1))\n    \n    for k, vals in history.history.items():\n        print('{}: {}'.format(k, vals[best_idx]))\n    \n    print('\\nRestoring best weights and predicting validation set.')\n    model.load_weights(best_weights_ph1)\n    model.save(f\"{dataset_name}_{name}_ph1_model.keras\")\n    \n    loss, acc = evaluate(model, x_test, y_test)\n    print('Transfer Learning test scores (loss, acc):', [loss, acc])\n    plot_acc(history, f\"\\n Transfer Learning - ACC: {name} PhA.\")\n    plot_loss(history, f\"\\n Transfer Learning - LOSS: {name} PhA.\")\n    y_pred = predict(model)\n    return history, model, val_acc_max, y_pred","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.53749Z","iopub.execute_input":"2024-04-19T08:46:34.537752Z","iopub.status.idle":"2024-04-19T08:46:34.551204Z","shell.execute_reply.started":"2024-04-19T08:46:34.537729Z","shell.execute_reply":"2024-04-19T08:46:34.550405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup fine tuning","metadata":{}},{"cell_type":"code","source":"def fine_turning(model, name, acc_ph1):\n    \n    best_weights_ph2 = f\"{dataset_name}_{name}_ph2_weights.keras\"\n    callbacks_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath = best_weights_ph2,\n        monitor = \"val_accuracy\",\n        mode = \"max\",\n        save_weights_only=True,\n        save_best_only = True,\n        verbose=1, # Logging when callback running\n    )\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.85, beta_2=0.9925)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    history = model.fit(\n        x_train, \n        y_train,\n        batch_size=BATCH_SIZE,\n        validation_data=(x_val, y_val),\n        validation_batch_size=BATCH_SIZE,\n        epochs = EPOCHS,\n        callbacks = [callbacks_checkpoint, early_stop, lr_callback]\n    )\n    \n    acc_max = max(history.history[\"accuracy\"])\n    acc_min = min(history.history[\"accuracy\"])\n    print(\"Training Acc:\", [acc_min, acc_max])\n    \n    val_acc_max = max(history.history[\"val_accuracy\"])\n    val_acc_min = min(history.history[\"val_accuracy\"])\n    print(\"Validation Acc:\", [val_acc_min, val_acc_max])\n    \n    best_idx = np.argmax(history.history[\"val_accuracy\"])\n    print('The best val_acc result expected at epoch {} with metrics: '.format(best_idx))\n    for k, vals in history.history.items():\n        print('{}: {}'.format(k, vals[best_idx]))\n    \n    print('Restoring best weights of Ph2 and predicting test set.')\n    model.load_weights(best_weights_ph2)\n    model.save(f\"{dataset_name}_{name}_ph2_model.keras\")\n    \n    loss, acc = evaluate(model, x_test, y_test)\n    print('Fine Tuning test scores (loss, acc):', [loss, acc])\n    \n    if val_acc_max < acc_ph1:\n        print('\\nPhase 2 resulted in lower accuracy than Phase 1.')\n    \n    plot_acc(history, f\"\\n Fine Tuning - ACC: {name} PhB.\")\n    plot_loss(history, f\"\\n Fine Tuning - LOSS: {name} PhB.\")\n    \n    y_pred = predict(model)\n    return history, model, val_acc_max, y_pred","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.552422Z","iopub.execute_input":"2024-04-19T08:46:34.553184Z","iopub.status.idle":"2024-04-19T08:46:34.566947Z","shell.execute_reply.started":"2024-04-19T08:46:34.55315Z","shell.execute_reply":"2024-04-19T08:46:34.566215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup save history","metadata":{}},{"cell_type":"code","source":"def save_history(history, path):\n    history_df = pd.DataFrame(data=history)\n    history_df.index.name = \"Epoch\"\n    history_df.to_csv(path)\n    print(\"Saved history completed.\")\n    print(history_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.568123Z","iopub.execute_input":"2024-04-19T08:46:34.568796Z","iopub.status.idle":"2024-04-19T08:46:34.579939Z","shell.execute_reply.started":"2024-04-19T08:46:34.568738Z","shell.execute_reply":"2024-04-19T08:46:34.579078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"markdown","source":"# Define Model Holder","metadata":{}},{"cell_type":"code","source":"class ExpModel:\n    \n    priority = 0\n    \n    def __init__(self, model, name, pretrained=True, priority=None, is_ready=True):\n        \n        self.model = model\n        self.name = name\n        self.pretrained = pretrained\n        self.priority = priority\n        if self.priority is None:\n            ExpModel.priority += 1\n            self.priority = ExpModel.priority\n        self.is_ready = is_ready\n\nexp_models = dict()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.580937Z","iopub.execute_input":"2024-04-19T08:46:34.581175Z","iopub.status.idle":"2024-04-19T08:46:34.593931Z","shell.execute_reply.started":"2024-04-19T08:46:34.581154Z","shell.execute_reply":"2024-04-19T08:46:34.593082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Model","metadata":{}},{"cell_type":"code","source":"def data_augumentation_layer():\n    \n    return tf.keras.Sequential([\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(0.02, fill_mode='constant'),\n        layers.RandomContrast(0.1),\n        layers.RandomZoom(height_factor=0.01, width_factor=0.05),\n        layers.RandomTranslation(height_factor=0.0015, width_factor=0.0015, fill_mode='constant'),\n    ], name=\"augumentation_layer\")\n\ndef build_model():\n    \n    x_input = tf.keras.Input(shape=INPUT_SHAPE)\n    \n    s1 = layers.Rescaling(1 / 255.0)(x_input)\n    a1 = data_augumentation_layer()(s1)\n    \n    c1 = layers.Conv2D(64, (5, 5), activation=\"relu\")(a1)\n    p1 = layers.MaxPooling2D(pool_size=(3, 3))(c1)\n    \n    c2 = layers.Conv2D(64, (5, 5), activation=\"relu\")(p1)\n    p2 = layers.MaxPooling2D(pool_size=(3, 3))(c2)\n    \n    c3 = layers.Conv2D(128, (4, 4), activation=\"relu\")(p2)\n    p3 = layers.MaxPooling2D(pool_size=(2, 2))(c3)\n    \n    c4 = layers.Conv2D(128, (4, 4), activation=\"relu\")(p3)\n    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n    \n    f1 = layers.Flatten()(p4)\n    \n    d1 = layers.Dense(512, activation=\"relu\")(f1)\n    output = layers.Dense(num_classes, activation=\"softmax\")(d1)\n    \n    return tf.keras.Model(x_input, output, name='ProposedModel')\n\nmodel = build_model()\nexp_models['Proposed Model'] = ExpModel(model, 'Proposed Model', pretrained=False, is_ready=True)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:34.594972Z","iopub.execute_input":"2024-04-19T08:46:34.595285Z","iopub.status.idle":"2024-04-19T08:46:35.268341Z","shell.execute_reply.started":"2024-04-19T08:46:34.595255Z","shell.execute_reply":"2024-04-19T08:46:35.267491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNetB3","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.EfficientNetB3(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dense(1024, activation='relu')(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='EfficientNetB3')\n\nmodel = build_model()\nexp_models['EfficientNetB3'] = ExpModel(model, 'EfficientNetB3', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:35.269529Z","iopub.execute_input":"2024-04-19T08:46:35.269804Z","iopub.status.idle":"2024-04-19T08:46:41.172431Z","shell.execute_reply.started":"2024-04-19T08:46:35.269781Z","shell.execute_reply":"2024-04-19T08:46:41.171553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet50","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.ResNet50(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='ResNet50')\n\nmodel = build_model()\nexp_models['ResNet50'] = ExpModel(model, 'ResNet50', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:41.173686Z","iopub.execute_input":"2024-04-19T08:46:41.173991Z","iopub.status.idle":"2024-04-19T08:46:46.666885Z","shell.execute_reply.started":"2024-04-19T08:46:41.173966Z","shell.execute_reply":"2024-04-19T08:46:46.665965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet169","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.DenseNet169(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='DenseNet169')\n\nmodel = build_model()\nexp_models['DenseNet169'] = ExpModel(model, 'DenseNet169', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:46.66815Z","iopub.execute_input":"2024-04-19T08:46:46.668541Z","iopub.status.idle":"2024-04-19T08:46:54.106765Z","shell.execute_reply.started":"2024-04-19T08:46:46.668508Z","shell.execute_reply":"2024-04-19T08:46:54.105778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Xception","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.Xception(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='Xception')\n\nmodel = build_model()\nexp_models['Xception'] = ExpModel(model, 'Xception', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:54.107939Z","iopub.execute_input":"2024-04-19T08:46:54.10823Z","iopub.status.idle":"2024-04-19T08:46:58.635126Z","shell.execute_reply.started":"2024-04-19T08:46:54.108204Z","shell.execute_reply":"2024-04-19T08:46:58.634177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNet","metadata":{}},{"cell_type":"code","source":"pretrained = tf.keras.applications.MobileNet(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)\npretrained.trainable = False\n\ndef build_model():\n    \n    x_input = pretrained.input\n    x = pretrained.output\n    x = layers.GlobalAvgPool2D()(x)\n    output = layers.Dense(num_classes, activation='softmax')(x)\n    \n    return tf.keras.Model(x_input, output, name='MobileNet')\n\nmodel = build_model()\nexp_models['MobileNet'] = ExpModel(model, 'MobileNet', is_ready=False)\nprint(f\"{model.name}: {len(model.layers)} layers. {(sum(layer.count_params() for layer in model.layers) / 1e6):.2f}M params.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:46:58.636551Z","iopub.execute_input":"2024-04-19T08:46:58.636831Z","iopub.status.idle":"2024-04-19T08:47:00.626133Z","shell.execute_reply.started":"2024-04-19T08:46:58.6368Z","shell.execute_reply":"2024-04-19T08:47:00.625035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"filtered_models = list(filter(lambda obj: obj.is_ready, sorted(exp_models.values(), key=lambda obj: obj.priority)))\nexpected_acc = 0.99\nfor current_model in filtered_models:\n    \n    best_acc = 0\n    print(f'\\n\\n ==========Start Process with model {current_model.name}=========')\n    if current_model.pretrained:\n        history, model, best_acc, y_pred = transfer_learning(current_model.model, current_model.name)\n        y_true = np.argmax(y_test, axis=1)\n        calculate_metrics(y_true, y_pred)\n        cm = confusion_matrix(y_true, y_pred)\n        plot_confusion_matrix(cm, classes, title=f\"Confusion matrix for {current_model.name} - Transfer Learning\")\n        save_history(history.history, f\"{current_model.name}-{dataset_name}-transfer-learning-results.csv\")\n    \n    if best_acc < expected_acc:\n        history, model, best_acc, y_pred = fine_turning(current_model.model, current_model.name, best_acc)\n        y_true = np.argmax(y_test, axis=1)\n        calculate_metrics(y_true, y_pred)\n        cm = confusion_matrix(y_true, y_pred)\n        plot_confusion_matrix(cm, classes, title=f\"Confusion matrix for {current_model.name} - Fine Turnning\")\n        save_history(history.history, f\"{current_model.name}-{dataset_name}-fine-tuning-results.csv\")\n    \n    print(\"Classification Report for {}\".format(current_model.name))\n    print(classification_report(y_true, y_pred, target_names=classes))\n    \n    \n    \n    print(f'\\n\\n ==========Completed Process with model {current_model.name}=========')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:47:00.627585Z","iopub.execute_input":"2024-04-19T08:47:00.62791Z","iopub.status.idle":"2024-04-19T08:51:07.652882Z","shell.execute_reply.started":"2024-04-19T08:47:00.627883Z","shell.execute_reply":"2024-04-19T08:51:07.651957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explainable SHAP","metadata":{}},{"cell_type":"code","source":"import shap","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:51:07.653929Z","iopub.execute_input":"2024-04-19T08:51:07.654213Z","iopub.status.idle":"2024-04-19T08:51:12.291385Z","shell.execute_reply.started":"2024-04-19T08:51:07.654189Z","shell.execute_reply":"2024-04-19T08:51:12.290604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def explain_model(model, arr, label, k=2):\n    \n    # define a masker that is used to mask out partitions of the input image.\n    masker = shap.maskers.Image(\"inpaint_telea\", INPUT_SHAPE)\n    # create an explainer with model and image masker\n    explainer = shap.Explainer(model, masker, output_names=classes)\n    \n    # here we explain two images using 512 evaluations of the underlying model to estimate the SHAP values\n    print('There are predicted results with model explaination:')\n    x_indices = np.random.choice(arr.shape[0], size=k, replace=False)\n    x_explained = arr[x_indices]\n    \n    for i in range(k):\n        shap_values = explainer(\n            x_explained[i:i+1], max_evals=512, batch_size=BATCH_SIZE, outputs=shap.Explanation.argsort.flip[:len(classes)]\n        )\n        # output with shap values\n        shap.image_plot(shap_values, true_labels=[label], labelpad=10)\n\nexplain_model","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:12:26.636359Z","iopub.execute_input":"2024-04-19T09:12:26.63674Z","iopub.status.idle":"2024-04-19T09:12:26.647105Z","shell.execute_reply.started":"2024-04-19T09:12:26.636714Z","shell.execute_reply":"2024-04-19T09:12:26.646212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explain_data = { ground_truth: np.stack(items, axis=0) for ground_truth, items in data_dict.items() }\nfor current_model in filtered_models:\n    if not current_model.is_ready: continue\n    print(f'Explain model for {current_model.name}')\n    for ground_truth, data in explain_data.items():\n        explain_model(current_model.model, data, ground_truth, 2)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:12:28.936726Z","iopub.execute_input":"2024-04-19T09:12:28.937425Z","iopub.status.idle":"2024-04-19T09:15:11.914683Z","shell.execute_reply.started":"2024-04-19T09:12:28.937393Z","shell.execute_reply":"2024-04-19T09:15:11.91378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test and Visualize Results","metadata":{}},{"cell_type":"code","source":"k = 5\nn = len(y_test)\nsample_idx = np.random.choice(range(n), k)\nx_sample = x_test[sample_idx]\ny_sample = y_test[sample_idx]\ny_sample","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:17:16.760307Z","iopub.execute_input":"2024-04-19T09:17:16.761252Z","iopub.status.idle":"2024-04-19T09:17:16.769086Z","shell.execute_reply.started":"2024-04-19T09:17:16.761216Z","shell.execute_reply":"2024-04-19T09:17:16.768119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams.update({'font.size': 16})\n\ndef format_label(label):\n    return '\\n'.join(label.split())\n\nshort_labels = list(map(format_label, classes))\nfor current_model in filtered_models:\n    if not current_model.is_ready: continue\n    model = current_model.model\n    print(\"\\n\\nPrediction for {} model\".format(current_model.name))\n    y_pred = model.predict(x_sample)\n    fig, ax = plt.subplots(k, 2, figsize=(30, 25))\n    y_true = np.argmax(y_sample, axis=1)\n    for i in range(k):\n        acc = y_pred[i] * 100\n        bar_colors = ['red', 'blue', 'green', 'orange', 'purple', 'gray', 'magenta']\n        ax[i, 0].imshow(x_sample[i] / 255)\n        ax[i, 0].axis('off')\n        ax[i, 1].bar(short_labels, acc, label=short_labels, color=[bar_colors[i % len(bar_colors)] for i in range(num_classes)])\n        ax[i, 1].set_ylabel('Predict')\n        ax[i, 1].set_title('Ground Truth: {}'.format(classes[y_true[i]]))\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:17:18.693552Z","iopub.execute_input":"2024-04-19T09:17:18.694206Z","iopub.status.idle":"2024-04-19T09:17:21.160094Z","shell.execute_reply.started":"2024-04-19T09:17:18.694177Z","shell.execute_reply":"2024-04-19T09:17:21.159167Z"},"trusted":true},"execution_count":null,"outputs":[]}]}